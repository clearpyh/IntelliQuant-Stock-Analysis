import os
import json
import pandas as pd
from typing import List, Dict, Any
from tools.llm_conclusion import generate_conclusions, generate_summary_text
from tools.llm_conclusion import generate_module_advice_human
from tools.llm_conclusion import generate_module_followup

def build_facts(df_symbol: pd.DataFrame, indicators: pd.DataFrame, corr: pd.DataFrame, explained, symbol: str, industry: str) -> Dict[str, Any]:
    facts = {
        "symbol": symbol,
        "industry": industry,
        "last_close": float(df_symbol["close"].iloc[-1]),
        "ma_slope": float(indicators["SMA"].diff().iloc[-1]) if "SMA" in indicators.columns else None,
        "ema_slope": float(indicators["EMA"].diff().iloc[-1]) if "EMA" in indicators.columns else None,
    }
    
    # Add recent price history for K-line analysis
    try:
        recent = df_symbol.tail(5).copy()
        if "date" in recent.columns:
            recent["date"] = recent["date"].astype(str)
        facts["recent_ohlcv"] = recent.to_dict(orient="records")
        
        # Calculate recent high/low for support/resistance context
        last_20 = df_symbol.tail(20)
        facts["recent_20d_high"] = float(last_20["high"].max())
        facts["recent_20d_low"] = float(last_20["low"].min())
    except Exception:
        pass

    if corr is not None:
        facts["industry_corr_mean"] = float(corr.mean().mean())
    if explained is not None:
        facts["pca_first_var"] = float(pd.Series(explained).iloc[0])
    try:
        facts["rsi_last"] = float(indicators["RSI"].iloc[-1]) if "RSI" in indicators.columns else None
    except Exception:
        facts["rsi_last"] = None
    return facts

def generate_conclusions_with_llm(facts: Dict[str, Any], chart_paths: List[str]) -> List[Dict[str, Any]]:
    endpoint = os.environ.get("LLM_ENDPOINT")
    api_key = os.environ.get("LLM_API_KEY")
    if not endpoint:
        return _rule_based_conclusions(facts, chart_paths)
    try:
        return generate_conclusions(facts, chart_paths, endpoint, api_key)
    except Exception:
        return _rule_based_conclusions(facts, chart_paths)

def _mk_item(i, title, summary, method, confidence, facts, chart_paths, advice):
    return {
        "id": f"C{i}",
        "title": title,
        "summary": summary,
        "method": method,
        "confidence": confidence,
        "metrics": facts,
        "evidence_refs": [{"type": "chart", "path": p} for p in chart_paths],
        "advice": advice,
        "risk_notes": ["éœ€ç»“åˆæ›´å¤šç»´åº¦æ•°æ®è¿›è¡Œç¡®è®¤"]
    }

def _rule_based_conclusions(facts: Dict[str, Any], chart_paths: List[str]) -> List[Dict[str, Any]]:
    out = []
    i = 1
    ma = facts.get("ma_slope")
    ema = facts.get("ema_slope")
    rsi = facts.get("rsi_last")
    corrm = facts.get("industry_corr_mean")
    pca1 = facts.get("pca_first_var")
    trend_up = (ma is not None and ma > 0) or (ema is not None and ema > 0)
    trend_down = (ma is not None and ma < 0) and (ema is not None and ema < 0)
    if trend_up:
        out.append(_mk_item(i, "è¶‹åŠ¿å‘ä¸Š", "å‡çº¿æ–œç‡ä¸ºæ­£ï¼Œä»·æ ¼å¤„äºä¸Šè¡Œè¶‹åŠ¿", "trend", 0.7, facts, chart_paths, "å…³æ³¨å›è°ƒä¹°å…¥"))
    else:
        out.append(_mk_item(i, "è¶‹åŠ¿ä¸å¼º", "å‡çº¿æ–œç‡ä¸æ˜¾è‘—ä¸ºæ­£ï¼Œéœ€ç­‰å¾…è¶‹åŠ¿ç¡®è®¤", "trend", 0.5, facts, chart_paths, "è§‚æœ›"))
    i += 1
    if trend_down:
        out.append(_mk_item(i, "è¶‹åŠ¿å‘ä¸‹", "å‡çº¿æ–œç‡ä¸ºè´Ÿï¼Œä»·æ ¼å¤„äºä¸‹é™è¶‹åŠ¿", "trend", 0.7, facts, chart_paths, "è°¨æ…ï¼Œé¿å…è¿½é«˜"))
    else:
        out.append(_mk_item(i, "è¶‹åŠ¿æœªè§æ˜æ˜¾ä¸‹è¡Œ", "å‡çº¿æ–œç‡æœªæ˜¾è‘—ä¸ºè´Ÿ", "trend", 0.5, facts, chart_paths, "ä¿æŒè§‚å¯Ÿ"))
    i += 1
    if rsi is not None and rsi < 30:
        out.append(_mk_item(i, "åŠ¨é‡åå¼±ä½†æˆ–æœ‰è¶…å–", "RSI<30ï¼Œå­˜åœ¨æŠ€æœ¯æ€§åå¼¹å¯èƒ½", "momentum", 0.6, facts, chart_paths, "å…³æ³¨åå¼¹ä¿¡å·"))
    elif rsi is not None and rsi > 70:
        out.append(_mk_item(i, "åŠ¨é‡åå¼ºæˆ–æœ‰è¶…ä¹°", "RSI>70ï¼ŒçŸ­æœŸæˆ–æœ‰å›è°ƒå‹åŠ›", "momentum", 0.6, facts, chart_paths, "åˆ†æ‰¹å‡ä»“"))
    else:
        out.append(_mk_item(i, "åŠ¨é‡ä¸­æ€§", "RSIä½äºä¸­æ€§åŒºåŸŸ", "momentum", 0.5, facts, chart_paths, "è§‚æœ›"))
    i += 1
    if corrm is not None:
        out.append(_mk_item(i, "è¡Œä¸šè”åŠ¨æ€§", f"è¡Œä¸šç›¸å…³æ€§å‡å€¼ä¸º{corrm:.2f}", "correlation", 0.5, facts, chart_paths, "æ³¨æ„æ¿å—å…±æŒ¯é£é™©"))
    else:
        out.append(_mk_item(i, "è¡Œä¸šè”åŠ¨ä¿¡æ¯ç¼ºå¤±", "æœªåŠ è½½åˆ°è¡Œä¸šç›¸å…³æ€§æ•°æ®", "correlation", 0.4, facts, chart_paths, "ä»¥ä¸ªè‚¡ä¸ºä¸»"))
    i += 1
    if pca1 is not None:
        out.append(_mk_item(i, "å¸‚åœºä¸»å› å­é©±åŠ¨", f"PCAç¬¬ä¸€å› å­è§£é‡Šç‡çº¦{pca1:.2f}", "pca", 0.5, facts, chart_paths, "ç»“åˆå› å­æš´éœ²è¯„ä¼°"))
    else:
        out.append(_mk_item(i, "ä¸»å› å­ä¿¡æ¯ç¼ºå¤±", "æœªåŠ è½½åˆ°PCAåˆ†è§£", "pca", 0.4, facts, chart_paths, "è¡¥å……æ•°æ®åå†è¯„ä¼°"))
    i += 1
    out.append(_mk_item(i, "é£é™©æ§åˆ¶å»ºè®®", "ç»“åˆæ³¢åŠ¨ä¸è¶‹åŠ¿ï¼Œä¸¥æ ¼è®¾ç½®æ­¢æŸä¸ä»“ä½æ§åˆ¶", "risk", 0.6, facts, chart_paths, "æ§åˆ¶ä»“ä½ä¸æ­¢æŸ"))
    i += 1
    out.append(_mk_item(i, "åˆ†æ‰¹å‚ä¸ç­–ç•¥", "è¶‹åŠ¿åˆæ­¥å½¢æˆæ—¶å¯åˆ†æ‰¹è¯•æ¢æ€§å‚ä¸", "strategy", 0.6, facts, chart_paths, "åˆ†æ‰¹ä¹°å…¥"))
    i += 1
    out.append(_mk_item(i, "å›æ’¤ä¸è€å¿ƒ", "è‹¥å›æ’¤æœªç ´å…³é”®æ”¯æ’‘ï¼Œå¯è€å¿ƒç­‰å¾…ä¸Šè¡Œç¡®è®¤", "risk", 0.5, facts, chart_paths, "ä¿æŒè€å¿ƒ"))
    i += 1
    out.append(_mk_item(i, "äº‹ä»¶ä¸åŸºæœ¬é¢è·Ÿè¸ª", "ç»“åˆè´¢æŠ¥ä¸è¡Œä¸šäº‹ä»¶ï¼Œé¿å…ä¿¡æ¯ç¼ºå£", "fundamental", 0.6, facts, chart_paths, "æŒç»­è·Ÿè¸ª"))
    i += 1
    out.append(_mk_item(i, "ç»¼åˆå»ºè®®", "å½“å‰ä¿¡å·ç»¼åˆè¯„ä¼°åç»™å‡ºæ“ä½œæè®®", "summary", 0.6, facts, chart_paths, "ç»“åˆé£é™©åå¥½æ‰§è¡Œ"))
    return out

def generate_conclusion_text(facts: Dict[str, Any], chart_paths: List[str]) -> str:
    endpoint = os.environ.get("LLM_ENDPOINT")
    api_key = os.environ.get("LLM_API_KEY")
    if not endpoint:
        return _rule_based_text(facts, chart_paths)
    try:
        return generate_summary_text(facts, chart_paths, endpoint, api_key)
    except Exception:
        return _rule_based_text(facts, chart_paths)

def generate_module_advice_text(module: str, inputs: Dict[str, Any], facts: Dict[str, Any]) -> str:
    endpoint = os.environ.get("LLM_ENDPOINT")
    api_key = os.environ.get("LLM_API_KEY")
    if not endpoint:
        return _rule_based_module_text(module, inputs, facts)
    try:
        return generate_module_advice_human(facts, module, inputs, endpoint, api_key)
    except Exception:
        return _rule_based_module_text(module, inputs, facts)

def generate_module_followup_text(module: str, inputs: Dict[str, Any], facts: Dict[str, Any], advisor_text: str, question: str) -> str:
    endpoint = os.environ.get("LLM_ENDPOINT")
    api_key = os.environ.get("LLM_API_KEY")
    if not endpoint:
        return _rule_based_module_followup(module, inputs, facts, advisor_text, question)
    try:
        return generate_module_followup(facts, module, inputs, advisor_text, question, endpoint, api_key)
    except Exception:
        return _rule_based_module_followup(module, inputs, facts, advisor_text, question)
def _rule_based_text(facts: Dict[str, Any], chart_paths: List[str]) -> str:
    lines = []
    lines.append(f"è¯åˆ¸ï¼š{facts.get('symbol','')} è¡Œä¸šï¼š{facts.get('industry','')}")
    lines.append(f"æœ€æ–°æ”¶ç›˜ï¼š{facts.get('last_close','')}ï¼›SMAæ–œç‡ï¼š{facts.get('ma_slope','')}ï¼›EMAæ–œç‡ï¼š{facts.get('ema_slope','')}")
    if 'industry_corr_mean' in facts:
        lines.append(f"è¡Œä¸šç›¸å…³æ€§å‡å€¼ï¼š{facts.get('industry_corr_mean')}")
    if 'pca_first_var' in facts:
        lines.append(f"PCAç¬¬ä¸€å› å­è§£é‡Šç‡ï¼š{facts.get('pca_first_var')}")
    for i in range(1, 11):
        lines.append(f"ç»“è®º{i}ï¼šåŸºäºå½“å‰æŠ€æœ¯ä¸è¡Œä¸šæŒ‡æ ‡çš„ç»¼åˆåˆ¤æ–­ï¼Œè¯·ç»“åˆå›¾è¡¨ä¸æ•°æ®è¿›è¡ŒéªŒè¯ã€‚")
    if chart_paths:
        lines.append("å›¾è¡¨ï¼š")
        for p in chart_paths:
            lines.append(f"- {p}")
    lines.append("é£é™©æç¤ºï¼šä»…åŸºäºå±€éƒ¨äº‹å®ï¼Œéœ€ç»“åˆæ›´å…¨é¢æ•°æ®ï¼›å¸‚åœºå­˜åœ¨æ ·æœ¬å¤–é£é™©ã€‚")
    return "\n".join(lines)

def _rule_based_module_text(module: str, inputs: Dict[str, Any], facts: Dict[str, Any]) -> str:
    s = facts.get("symbol", "")
    ind = facts.get("industry", "")
    rng = inputs.get("time_range") or ""
    lines = []
    if module == "Kçº¿ä¸æŒ‡æ ‡":
        ma = facts.get("ma_slope"); ema = facts.get("ema_slope")
        dir_txt = "ä¸­æ€§åè°¨æ…" if not ((ma and ma > 0) or (ema and ema > 0)) else "åå¤šä½†éœ€è°¨æ…"
        lines.append(f"ç»“è®ºï¼šåœ¨{rng}åŒºé—´ï¼Œ{s}ï¼ˆ{ind}ï¼‰èµ°åŠ¿{dir_txt}ã€‚")
        lines.append("å»ºè®®ï¼šè½»ä»“è§‚å¯Ÿï¼Œæ¶¨å¹…ä¼´éšæ”¾é‡ä¸”ç«™ç¨³å…³é”®å‡çº¿æ—¶å†è·Ÿéšï¼›ä»»ä½•ä»“ä½éƒ½é…æ­¢æŸã€‚")
    elif module == "ç›¸å…³æ€§åˆ†æ":
        m = facts.get("industry_corr_mean"); tag = "è”åŠ¨æ€§è¾ƒé«˜ï¼Œåˆ†æ•£æ•ˆæœæœ‰é™" if (m and m >= 0.6) else "è”åŠ¨æ€§ä¸­ç­‰æˆ–åä½"
        lines.append(f"ç»“è®ºï¼šæ¿å—{tag}ã€‚")
        lines.append("å»ºè®®ï¼šé™ä½æ€»ä»“ä½ï¼Œé¿å…åŒç±»æ ‡çš„é›†ä¸­æŒæœ‰ï¼Œä¼˜å…ˆé€‰æ‹©å…³è”åº¦ä½çš„è¡¥å……é…ç½®ã€‚")
    elif module == "PCAåˆ†æ":
        p1 = facts.get("pca_first_var"); tag = "å°‘æ•°å› å­ä¸»å¯¼ï¼Œå¸‚åœºæ›´ä¸€è¾¹å€’" if (p1 and p1 >= 0.4) else "å› å­åˆ†æ•£ï¼Œç»“æ„è¾ƒå‡è¡¡"
        lines.append(f"ç»“è®ºï¼š{tag}ã€‚")
        lines.append("å»ºè®®ï¼šé¿å…å•ä¸€é£æ ¼é‡ä»“ï¼Œåˆ†æ•£åˆ°ä¸åŒé£æ ¼ä¸è¡Œä¸šï¼Œé™ä½ç³»ç»Ÿæ€§é£é™©ã€‚")
    elif module == "æ³¢åŠ¨æ€§åˆ†æ":
        lines.append("ç»“è®ºï¼šæ³¢åŠ¨æ€§åé«˜ï¼Œå›æ’¤é£é™©å¢åŠ ã€‚")
        lines.append("å»ºè®®ï¼šç¼©çŸ­æŒä»“å‘¨æœŸï¼Œå‡å°ä»“ä½ï¼›åªåœ¨å›æ’¤å—æ§ä¸”è¶‹åŠ¿æ”¹å–„æ—¶å¢åŠ æš´éœ²ã€‚")
    elif module == "å­£èŠ‚æ€§åˆ†æ":
        lines.append("ç»“è®ºï¼šå­˜åœ¨å¯è¯†åˆ«çš„èŠ‚å¥ä¸å‘¨æœŸã€‚")
        lines.append("å»ºè®®ï¼šæŒ‰èŠ‚å¥åˆ†æ‰¹å¸ƒå±€ï¼Œé¿å¼€éšæœºæ³¢åŠ¨å¢å¼ºé˜¶æ®µçš„æ¿€è¿›æ“ä½œã€‚")
    elif module == "é£é™©-æ”¶ç›Šèšç±»åˆ†æ":
        lines.append("ç»“è®ºï¼šä¸åŒæ ‡çš„é£é™©ç‰¹å¾å·®å¼‚æ˜¾è‘—ã€‚")
        lines.append("å»ºè®®ï¼šç¨³å¥å‹ä¼˜å…ˆä½æ³¢åŠ¨ç°‡ï¼Œè¿›å–å‹å¯å…³æ³¨é«˜å›æŠ¥ç°‡ä½†å¿…é¡»é…å¥—é£é™©æ§åˆ¶ã€‚")
    elif module == "åŸºæœ¬é¢å› å­æš´éœ²åˆ†æ":
        lines.append("ç»“è®ºï¼šåŸºæœ¬é¢å› å­èƒ½éƒ¨åˆ†è§£é‡Šæ”¶ç›Šï¼Œä½†å¹¶éç¡®å®šæ€§ã€‚")
        lines.append("å»ºè®®ï¼šç»“åˆç›ˆåˆ©è´¨é‡ã€ç°é‡‘æµä¸è´Ÿå€ºç»“æ„ï¼Œå¤šç»´éªŒè¯åå†åšåŠ ä»“å†³ç­–ã€‚")
    elif module == "æ¶¨è·Œæ¦‚ç‡åˆ†æ":
        lines.append("ç»“è®ºï¼šæ¦‚ç‡å€¾å‘ä»…ä½œå‚è€ƒï¼Œä¸ç­‰åŒç¡®å®šæ€§ã€‚")
        lines.append("å»ºè®®ï¼šæŒ‰æ¦‚ç‡ä¼˜åŠ¿ä¼˜åŒ–ä»“ä½ç»“æ„ï¼Œä½†æ¯ç¬”äº¤æ˜“éƒ½é…æ­¢æŸä¸é€€å‡ºè§„åˆ™ã€‚")
    else:
        lines.append("ç»“è®ºï¼šå½“å‰ä¿¡å·ä¸­æ€§åè°¨æ…ï¼Œæ›´é€‚åˆç¨³å¥å‹ã€‚")
    lines.append("å»ºè®®ï¼ˆå¯æ‰§è¡Œä½†éæ‰¿è¯ºï¼‰ï¼š")
    lines.append("ç¨³å¥å‹ï¼šä»“ä½10%-30%ï¼Œæ­¢æŸ3%-5%ï¼›ç¡®è®¤åŸºæœ¬é¢æ”¹å–„æˆ–è¶‹åŠ¿å…±æŒ¯åå†æé«˜æš´éœ²ã€‚")
    lines.append("è¿›å–å‹ï¼šä»“ä½30%-50%ï¼Œæ­¢æŸ5%-8%ï¼›ä»…åœ¨é‡ä»·é…åˆä¸”å›æ’¤å—æ§æ—¶åŠ ä»“ã€‚")
    lines.append("å·²æŒæœ‰è€…ï¼šä»¥é£é™©é¢„ç®—ä¸ºå…ˆï¼Œçªç ´å…³é”®ä½æˆ–åŸºæœ¬é¢æ”¹å–„å†è€ƒè™‘åŠ ä»“ã€‚")
    return "\n".join(lines)

def _rule_based_module_followup(module: str, inputs: Dict[str, Any], facts: Dict[str, Any], advisor_text: str, question: str) -> str:
    q = (question or "").strip()
    if not q:
        return "è¯·æ˜ç¡®ä½ çš„é—®é¢˜ï¼Œä¾‹å¦‚â€œæ˜¯å¦é€‚åˆåŠ ä»“ï¼Ÿâ€æˆ–â€œå½“å‰é£é™©ä¸»è¦æ¥è‡ªå“ªé‡Œï¼Ÿâ€"
    s = facts.get("symbol",""); ind = facts.get("industry","")
    rng = inputs.get("time_range","")
    last = facts.get("last_close")
    ma = facts.get("ma_slope"); ema = facts.get("ema_slope"); rsi = facts.get("rsi_last")
    corrm = facts.get("industry_corr_mean"); pca1 = facts.get("pca_first_var")
    hi20 = facts.get("recent_20d_high"); lo20 = facts.get("recent_20d_low")
    def _yn(b): return "æ˜¯" if b else "å¦"
    def _fmt(x, pct=False):
        if x is None: return "N/A"
        try:
            return f"{x:.2%}" if pct else f"{x:.2f}"
        except Exception:
            return str(x)
    ql = q.lower()
    ans = []
    ans.append(f"{s}ï¼ˆ{ind}ï¼‰| åŒºé—´ï¼š{rng} | é—®é¢˜ï¼š{q}")
    if "åŠ ä»“" in q or "ä¹°å…¥" in q or "å¢æŒ" in q:
        trend_up = ((ma or 0) > 0) or ((ema or 0) > 0)
        ok = trend_up and (rsi is None or rsi <= 70)
        ans.append(f"ç»“è®ºï¼š{_yn(ok)}ï¼Œæ›´åå‘åœ¨è¶‹åŠ¿è½¬æ­£ä¸”æœªæ˜¾è‘—è¶…ä¹°æ—¶åˆ†æ‰¹åŠ ä»“ã€‚")
        ans.append(f"ä¾æ®ï¼šSMAæ–œç‡={_fmt(ma)}ï¼ŒEMAæ–œç‡={_fmt(ema)}ï¼ŒRSI={_fmt(rsi)}ï¼›æ”¯æ’‘ä½â‰ˆ{_fmt(lo20)}ï¼Œå‹åŠ›ä½â‰ˆ{_fmt(hi20)}ï¼Œæœ€æ–°æ”¶ç›˜={_fmt(last)}ã€‚")
        ans.append("å»ºè®®ï¼šè‹¥æ”¶ç›˜ä»·ç«™ç¨³æ”¯æ’‘å¹¶çªç ´å…³é”®å‡çº¿ï¼Œå°‘é‡è¯•æ¢ï¼›ä»»æ„åŠ ä»“å‡é…3%-5%æ­¢æŸã€‚")
    elif "å‡ä»“" in q or "å–å‡º" in q or "æ­¢ç›ˆ" in q:
        overbought = (rsi is not None and rsi >= 70)
        trend_down = ((ma or 0) < 0) and ((ema or 0) < 0)
        need_trim = overbought or trend_down
        ans.append(f"ç»“è®ºï¼š{_yn(need_trim)}ï¼Œåœ¨è¶…ä¹°æˆ–è¶‹åŠ¿è½¬è´Ÿæ—¶ä¼˜å…ˆå‡ä»“ã€‚")
        ans.append(f"ä¾æ®ï¼šRSI={_fmt(rsi)}ï¼ŒSMAæ–œç‡={_fmt(ma)}ï¼ŒEMAæ–œç‡={_fmt(ema)}ï¼›å‹åŠ›ä½â‰ˆ{_fmt(hi20)}ã€‚")
        ans.append("å»ºè®®ï¼šåˆ†æ‰¹å‡ä»“ï¼Œè·Œç ´æ”¯æ’‘ä½æˆ–å…³é”®å‡çº¿æ—¶åŠ é€Ÿé€€å‡ºã€‚")
    elif "é£é™©" in q or "æ³¢åŠ¨" in q or "ä¸‹è¡Œ" in q:
        ans.append("ç»“è®ºï¼šé£é™©ä¸»è¦æ¥è‡ªè¶‹åŠ¿ä¸ç¨³ä¸è¡Œä¸šè”åŠ¨æ€§ã€‚")
        ans.append(f"ä¾æ®ï¼šSMAæ–œç‡={_fmt(ma)}ï¼ŒEMAæ–œç‡={_fmt(ema)}ï¼›è¡Œä¸šç›¸å…³æ€§å‡å€¼={_fmt(corrm)}ï¼›ä¸»å› å­è§£é‡Šç‡={_fmt(pca1)}ã€‚")
        ans.append("å»ºè®®ï¼šæé«˜æ­¢æŸçºªå¾‹ï¼Œé™ä½åŒè´¨åŒ–æŒä»“ï¼Œå¼•å…¥ä½ç›¸å…³æ¿å—åˆ†æ•£ã€‚")
    elif "æ”¯æ’‘" in q or "å‹åŠ›" in q or "å…³é”®ä½" in q:
        ans.append(f"ç»“è®ºï¼šè¿‘æœŸæ”¯æ’‘â‰ˆ{_fmt(lo20)}ï¼Œå‹åŠ›â‰ˆ{_fmt(hi20)}ï¼Œæœ€æ–°æ”¶ç›˜={_fmt(last)}ã€‚")
        ans.append("å»ºè®®ï¼šé è¿‘æ”¯æ’‘è§‚å¯Ÿåå¼¹ä¿¡å·ï¼›çªç ´å‹åŠ›å¹¶æ”¾é‡æ—¶å†å…³æ³¨è·Ÿéšã€‚")
    elif "ç›¸å…³æ€§" in q or "åˆ†æ•£" in q or "è”åŠ¨" in q:
        ans.append(f"ç»“è®ºï¼šè¡Œä¸šå¹³å‡ç›¸å…³æ€§â‰ˆ{_fmt(corrm)}ã€‚ç›¸å…³æ€§é«˜æ—¶åˆ†æ•£æ•ˆæœå¼±ã€‚")
        ans.append("å»ºè®®ï¼šè¡¥å……ä½ç›¸å…³æˆ–è´Ÿç›¸å…³è¡Œä¸šçš„é…ç½®ä»¥é™ä½ç»„åˆæ³¢åŠ¨ã€‚")
    elif "pca" in q.lower() or "å› å­" in q or "è§£é‡Šç‡" in q:
        ans.append(f"ç»“è®ºï¼šç¬¬ä¸€ä¸»æˆåˆ†è§£é‡Šç‡â‰ˆ{_fmt(pca1)}ã€‚è§£é‡Šç‡é«˜æ„å‘³é£æ ¼é›†ä¸­åº¦æå‡ã€‚")
        ans.append("å»ºè®®ï¼šé¿å…å•ä¸€é£æ ¼é‡ä»“ï¼Œæ‹‰å¹³è¡Œä¸šä¸é£æ ¼æš´éœ²ã€‚")
    elif "æ¦‚ç‡" in q or "ä¸Šæ¶¨" in q or "ä¸‹è·Œ" in q:
        ans.append("ç»“è®ºï¼šæ¦‚ç‡å€¾å‘éœ€ç»“åˆæ ·æœ¬ä¸AUCè¯„ä¼°ï¼Œé€‚åˆç”¨äºæ’åºä¸æƒé‡å¾®è°ƒã€‚")
        ans.append("å»ºè®®ï¼šä»…åœ¨æ¦‚ç‡ä¼˜åŠ¿ä¸åŸºæœ¬é¢æ”¹å–„å…±æŒ¯æ—¶æé«˜æš´éœ²ï¼›å§‹ç»ˆé…æ­¢æŸã€‚")
    else:
        ans.append("ç»“è®ºï¼šå½“å‰ä»¥è¶‹åŠ¿ä¸ä½ç½®ä¸ºä¸»ï¼Œç»“åˆåŸºæœ¬é¢ä¸è¡Œä¸šç¯å¢ƒç»¼åˆåˆ¤æ–­ã€‚")
        ans.append(f"ä¾æ®ï¼šSMAæ–œç‡={_fmt(ma)}ï¼ŒEMAæ–œç‡={_fmt(ema)}ï¼ŒRSI={_fmt(rsi)}ï¼Œæ”¯æ’‘â‰ˆ{_fmt(lo20)}ï¼Œå‹åŠ›â‰ˆ{_fmt(hi20)}ï¼Œç›¸å…³æ€§å‡å€¼â‰ˆ{_fmt(corrm)}ã€‚")
        ans.append("å»ºè®®ï¼šåˆ†æ‰¹æ“ä½œã€æ§åˆ¶ä»“ä½ä¸æ­¢æŸï¼Œç­‰å¾…æ˜ç¡®ä¿¡å·å†è°ƒæ•´ã€‚")
    return "\n".join(ans)
def generate_industry_analysis(summary) -> str:
    ind = str(summary.get("industry", ""))
    syms = summary.get("selected_stocks") or []
    scores = summary.get("scores") or {}
    baseline = summary.get("baseline") or {}
    core = summary.get("core_metrics") or {}

    items = []
    # ç”Ÿæˆæ¯åªè‚¡ç¥¨çš„ç»¼åˆè¯„åˆ†å’Œè§£è¯»
    for s in syms:
        row = scores.get(s) or {}
        sc = float(row.get("composite_score", 0.0))
        core_row = core.get(s) or {}
        dd = core_row.get("æœ€å¤§å›æ’¤")
        shp = core_row.get("å¤æ™®æ¯”ç‡")
        vol = core_row.get("æ³¢åŠ¨ç‡")
        # é»˜è®¤è§£è¯»
        comment = "æˆé•¿æ½œåŠ›å¯å…³æ³¨"
        try:
            if shp is not None and dd is not None:
                if abs(dd) <= 0.15 and shp >= 1.0:
                    comment = "ç›ˆåˆ©ç¨³å®šã€å›æ’¤ç›¸å¯¹å°"
                elif abs(dd) <= 0.20 and shp >= 0.8:
                    comment = "æ€§ä»·æ¯”è¾ƒä¼˜ï¼Œé£é™©é€‚ä¸­"
            elif vol is not None and baseline.get("avg_volatility") is not None:
                if vol <= float(baseline.get("avg_volatility")) and (shp or 0.0) >= 0.7:
                    comment = "æ³¢åŠ¨ç›¸å¯¹å¯æ§ï¼Œç¨³å¥åå¥½å¯å…³æ³¨"
        except Exception:
            pass
        items.append({"symbol": s, "score": sc, "drawdown": dd, "comment": comment})

    # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
    items = sorted(items, key=lambda x: x["score"], reverse=True)

    # ç¼©æ”¾åˆ†æ•°åˆ° 10 åˆ†åˆ¶
    sc_vals = [it["score"] for it in items] if items else [0.0]
    sc_min, sc_max = min(sc_vals), max(sc_vals)

    def _scale10(x: float) -> float:
        return 7.0 if sc_max == sc_min else (x - sc_min) / (sc_max - sc_min) * 10.0

    # è¡Œä¸šé˜¶æ®µä¸æ³¢åŠ¨æè¿°
    phase = str(baseline.get("mood") or "éœ‡è¡")
    avg_vol = float(baseline.get("avg_volatility") or 0.0)
    vol_desc = "å¹…åº¦æœ‰é™" if avg_vol < 0.20 else "ä¸­ç­‰æ³¢åŠ¨" if avg_vol < 0.35 else "æ³¢åŠ¨åå¤§"

    # ç”ŸæˆæŠ¥å‘Š
    def add_section(title: str, content: List[str]) -> List[str]:
        return [title] + [""] + content + [""]

    lines = []
    lines.append(f"å°é‡‘ Â· è¡Œä¸šæŠ•èµ„ç»“è®ºï¼ˆ{ind}ï¼‰")
    # æ ¸å¿ƒåˆ¤æ–­
    lines += add_section("ä¸€ã€æ ¸å¿ƒåˆ¤æ–­", [
        f"å½“å‰ {ind} è¡Œä¸šçŸ­æœŸèµ°åŠ¿ {phase}ï¼Œæ¶¨è·Œå¹… {vol_desc}ï¼Œ",
        "å»ºè®®ä¼˜å…ˆå…³æ³¨ç»¼åˆè¯„åˆ†é å‰çš„æ ‡çš„ï¼Œé‡‡å–åˆ†æ‰¹å‚ä¸ç­–ç•¥ï¼Œå¹¶ä»¥é£é™©é¢„ç®—ä¸ºå…ˆã€‚"
    ])
    # ä¼˜é€‰æ ‡çš„
    lines += add_section("äºŒã€ä¼˜é€‰æ ‡çš„ï¼ˆæŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼‰", [
        "è¯åˆ¸ä»£ç \té˜¶æ®µæ€§è¡¨ç°\tç»¼åˆè¯„åˆ†\tå°é‡‘ä¸€å¥è¯è§£è¯»"
    ] + [
        f"{it['symbol']}\t{(it['drawdown']*100 if it['drawdown'] is not None else 'N/A'):.1f}%\t{_scale10(it['score']):.1f}/10\t{it['comment']}"
        for it in items
    ] + ["å»ºè®®é¿å…ä¸€æ¬¡æ€§é‡ä»“ï¼Œå¯åˆ†æ‰¹å¸ƒå±€ã€‚"])

    # æ¨¡å‹ä¾æ®
    lines += add_section("ä¸‰ã€æ¨¡å‹ä¾æ®", [
        "æœ¬æ¬¡ç­›é€‰åŸºäºä»¥ä¸‹æ ¸å¿ƒç»´åº¦çš„ç»¼åˆè¯„ä¼°ï¼š",
        "ç›ˆåˆ©è´¨é‡ï¼šèµšé’±èƒ½åŠ›æ˜¯å¦ç¨³å®š",
        "å¿å€ºç»“æ„ï¼šè´¢åŠ¡æŠ—é£é™©èƒ½åŠ›",
        "æˆé•¿åŠ¨èƒ½ï¼šæœªæ¥ä¸šç»©å¢é•¿æ½œåŠ›",
        "æŠ•èµ„å›æŠ¥ï¼šè‚¡ä¸œå›æŠ¥æ°´å¹³",
        "ç»¼åˆè¯„åˆ†è¶Šé«˜ï¼Œä»£è¡¨å…¶åœ¨è¡Œä¸šå†…ç›ˆåˆ©èƒ½åŠ›ã€ç¨³å®šæ€§ä¸æˆé•¿æ€§æ›´å‡è¡¡ã€‚"
    ])

    # é£é™©æç¤º
    risks = summary.get("risk_factors") or [
        "è¡Œä¸šæ™¯æ°”åº¦æ³¢åŠ¨å¯èƒ½å¯¼è‡´è‚¡ä»·çŸ­æœŸå›è½",
        "ç›ˆåˆ©ä¸åŠé¢„æœŸå¯èƒ½æ‹–ç´¯æŠ•èµ„æ”¶ç›Š",
        "æµåŠ¨æ€§é£é™©å¯èƒ½å½±å“ä¹°å–æ“ä½œ",
        "æ”¿ç­–å˜åŒ–å¯èƒ½å¸¦æ¥è¡Œä¸šè°ƒæ•´"
    ]
    lines += add_section("å››ã€ä¸»è¦é£é™©æç¤º", risks + ["è¡Œä¸šæ³¢åŠ¨æˆ–å¤–éƒ¨ç¯å¢ƒå˜åŒ–ï¼Œå‡å¯èƒ½å¯¹çŸ­æœŸè¡¨ç°é€ æˆå½±å“ã€‚"])

    # æ“ä½œå»ºè®®
    lines += add_section("äº”ã€æ“ä½œå»ºè®®ï¼ˆæŒ‰é£é™©åå¥½ï¼‰", [
        "æŠ•èµ„è€…ç±»å‹\tå»ºè®®ä»“ä½\tæ­¢æŸåŒºé—´\tåŠ ä»“æ¡ä»¶",
        "ç¨³å¥å‹ ğŸ›¡\t10%-30%\t3%-5%\tç›ˆåˆ©ä¸ç°é‡‘æµæ”¹å–„ï¼Œä¼°å€¼åˆç†æ—¶åˆ†æ‰¹åŠ ä»“",
        "è¿›å–å‹ ğŸš€\t30%-50%\t5%-8%\té‡ä»·é…åˆè‰¯å¥½ï¼ŒåŸºæœ¬é¢æ”¹å–„æ—¶åˆ†æ‰¹åŠ ä»“",
        "å·²æŒæœ‰ ğŸ“Š\tåŠ¨æ€è°ƒæ•´\tæŒ‰é£é™©é¢„ç®—\tå…³é”®ä½çªç ´æˆ–åŸºæœ¬é¢æ”¹å–„å†åŠ ä»“"
    ])

    # å¤ç›˜è§¦å‘æ¡ä»¶
    triggers = summary.get("review_triggers") or ["å®šæœŸè´¢æŠ¥æŠ«éœ²", "è¡Œä¸šé‡å¤§äº‹ä»¶", "å…³é”®æŠ€æœ¯ä½çªç ´æˆ–å¤±å®ˆ"]
    lines += add_section("å…­ã€å¤ç›˜ä¸å†è¯„ä¼°è§¦å‘æ¡ä»¶", ["å»ºè®®åœ¨ä»¥ä¸‹æƒ…å†µå‡ºç°æ—¶ï¼Œå¯¹æŒä»“è¿›è¡Œå¤ç›˜ï¼š"] + triggers)

    # å°é‡‘æ€»ç»“
    lines += add_section("ä¸ƒã€å°é‡‘ä¸€å¥è¯æ€»ç»“", [
        str(summary.get("summary_sentence") or "è¿™ä¸æ˜¯æ‹¼çŸ­æœŸåšå¼ˆçš„è¡Œä¸šï¼Œè€Œæ˜¯ä¸€ä¸ªè®²èŠ‚å¥ã€è®²çºªå¾‹ã€è®²é£é™©æ§åˆ¶çš„é…ç½®æ–¹å‘ã€‚")
    ])

    return "\n".join(lines)
