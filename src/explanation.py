import pandas as pd
import numpy as np
from typing import Dict, Any, List

def _get_status_icon(sentiment: str) -> str:
    if sentiment == "positive": return "ğŸŸ¢"
    if sentiment == "negative": return "ğŸ”´"
    if sentiment == "warning": return "ğŸŸ "
    return "âšª"

def explain_trend_adx(df: pd.DataFrame, adx_series: pd.Series, ma_short: int, ma_long: int) -> Dict[str, Any]:
    """
    Analyzes Trend Strength and Sustainability.
    Core Question: "Is the trend strong or weak? Is it sustainable?"
    """
    if df.empty or adx_series.empty:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
    
    last_close = df["close"].iloc[-1]
    last_adx = adx_series.iloc[-1]
    
    # Calculate MAs if not present
    sma = df["close"].rolling(ma_short).mean()
    lma = df["close"].rolling(ma_long).mean()
    
    last_sma = sma.iloc[-1]
    last_lma = lma.iloc[-1]
    
    # Trend Direction
    if last_close > last_sma > last_lma:
        direction = "Bullish (å¤šå¤´)"
        sentiment = "positive"
    elif last_close < last_sma < last_lma:
        direction = "Bearish (ç©ºå¤´)"
        sentiment = "negative"
    else:
        direction = "Uncertain/Consolidation (éœ‡è¡)"
        sentiment = "neutral"
        
    # Trend Strength (ADX)
    if last_adx < 20:
        strength = "Weak (å¼±åŠ¿)"
        sustainability = "è¶‹åŠ¿ä¸æ˜æ˜¾ï¼Œå¸‚åœºå¤„äºéœ‡è¡æ•´ç†é˜¶æ®µ"
        advice = "å½“å‰ç¼ºä¹æ˜ç¡®è¶‹åŠ¿ï¼Œå»ºè®®è§‚æœ›æˆ–é‡‡ç”¨åŒºé—´äº¤æ˜“ç­–ç•¥ï¼ˆé«˜æŠ›ä½å¸ï¼‰ã€‚ä¸å®œè¿½æ¶¨æ€è·Œã€‚"
    elif 20 <= last_adx < 40:
        strength = "Moderate (ä¸­ç­‰)"
        sustainability = "è¶‹åŠ¿æ­£åœ¨å½¢æˆæˆ–ç¨³æ­¥è¿è¡Œ"
        advice = f"å½“å‰å¤„äº{direction}è¶‹åŠ¿ä¸­ï¼Œä¸”å…·å¤‡ä¸€å®šå¼ºåº¦ã€‚å»ºè®®é¡ºåŠ¿è€Œä¸ºã€‚"
    elif 40 <= last_adx < 60:
        strength = "Strong (å¼ºåŠ²)"
        sustainability = "è¶‹åŠ¿éå¸¸å¼ºåŠ²ï¼Œéœ€å…³æ³¨å»¶ç»­æ€§"
        advice = f"è¶‹åŠ¿å¼ºåŠ²ï¼Œä¸»è¦æŒæœ‰ä»“ä½ã€‚ä½†éœ€è­¦æƒ•çŸ­æœŸä¹–ç¦»è¿‡å¤§åçš„å›è°ƒé£é™©ã€‚"
    else:
        strength = "Extreme (æå¼º)"
        sustainability = "è¶‹åŠ¿æåº¦å¼ºåŠ²ï¼Œå¯èƒ½é¢ä¸´è¡°ç«­æˆ–åè½¬"
        advice = "å¸‚åœºæƒ…ç»ªå¯èƒ½è¿‡çƒ­ï¼ˆæˆ–è¿‡æï¼‰ï¼Œè¶‹åŠ¿éšæ—¶å¯èƒ½åè½¬ã€‚å»ºè®®æ”¶ç´§æ­¢æŸï¼Œé€‚å½“æ­¢ç›ˆï¼Œåˆ‡å‹¿ç›²ç›®åŠ ä»“ã€‚"

    return {
        "valid": True,
        "title": "è¶‹åŠ¿å¼ºåº¦ä¸æ–¹å‘åˆ†æ",
        "signal": f"{direction} | ADX: {last_adx:.1f} ({strength})",
        "assessment": f"å½“å‰ä»·æ ¼å¤„äº{direction}çŠ¶æ€ã€‚ADXæŒ‡æ ‡æ˜¾ç¤ºè¶‹åŠ¿å¼ºåº¦ä¸º{strength}ã€‚{sustainability}ã€‚",
        "advice": advice,
        "sentiment": sentiment,
        "question": "å½“å‰è¶‹åŠ¿æ˜¯å¼ºè¿˜æ˜¯å¼±ï¼Ÿæ˜¯å¦å…·å¤‡æŒç»­æ€§ï¼Ÿ"
    }

def explain_volatility_risk(vol_series: pd.Series, garch_forecast_variance=None) -> Dict[str, Any]:
    """
    Analyzes Volatility Risk.
    Core Question: "What is the risk level? Suitable for ordinary investors?"
    """
    if vol_series.empty:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
    
    current_vol = vol_series.iloc[-1]
    avg_vol = vol_series.mean()
    
    # Risk Level Assessment
    ratio = current_vol / avg_vol if avg_vol > 0 else 1.0
    
    if ratio < 0.8:
        level = "Low (ä½é£é™©)"
        desc = "å½“å‰æ³¢åŠ¨ç‡ä½äºå†å²å¹³å‡æ°´å¹³ï¼Œå¸‚åœºæƒ…ç»ªç›¸å¯¹å¹³ç¨³ã€‚"
        suitability = "é€‚åˆå¤§å¤šæ•°æŠ•èµ„è€…å‚ä¸ï¼Œä½†éœ€è­¦æƒ•æ³¢åŠ¨ç‡å›å½’ï¼ˆå˜ç›˜ï¼‰ã€‚"
        sentiment = "positive"
    elif 0.8 <= ratio < 1.2:
        level = "Normal (æ­£å¸¸)"
        desc = "å½“å‰æ³¢åŠ¨ç‡å¤„äºæ­£å¸¸èŒƒå›´å†…ã€‚"
        suitability = "é€‚åˆå…·å¤‡åŸºæœ¬é£é™©æ‰¿å—èƒ½åŠ›çš„æŠ•èµ„è€…ã€‚"
        sentiment = "neutral"
    elif 1.2 <= ratio < 2.0:
        level = "High (é«˜é£é™©)"
        desc = "å½“å‰æ³¢åŠ¨ç‡æ˜¾è‘—é«˜äºå¹³å‡æ°´å¹³ï¼Œå¸‚åœºå‰§çƒˆæ³¢åŠ¨ã€‚"
        suitability = "é£é™©è¾ƒé«˜ï¼Œä»…é€‚åˆé£é™©åå¥½è¾ƒé«˜çš„æ¿€è¿›æŠ•èµ„è€…ã€‚"
        sentiment = "warning"
    else:
        level = "Extreme (æé«˜é£é™©)"
        desc = "å¸‚åœºå¤„äºæç«¯æ³¢åŠ¨çŠ¶æ€ï¼Œææ…Œæˆ–ç‹‚çƒ­æƒ…ç»ªä¸»å¯¼ã€‚"
        suitability = "æä¸é€‚åˆæ™®é€šæŠ•èµ„è€…ï¼Œå»ºè®®ç©ºä»“æˆ–æè½»ä»“è§‚æœ›ã€‚"
        sentiment = "negative"

    garch_msg = ""
    if garch_forecast_variance is not None:
        garch_vol = np.sqrt(garch_forecast_variance)
        garch_msg = f"GARCHæ¨¡å‹é¢„æµ‹ä¸‹ä¸€æœŸæ³¢åŠ¨ç‡å¯èƒ½ä¸º {garch_vol:.4f}ã€‚"

    return {
        "valid": True,
        "title": "é£é™©æ°´å¹³è¯„ä¼° (åŸºäºæ³¢åŠ¨ç‡)",
        "signal": f"é£é™©ç­‰çº§: {level}",
        "assessment": f"{desc} (å½“å‰/å‡å€¼ = {ratio:.2f})ã€‚{garch_msg}",
        "advice": f"{suitability} å»ºè®®æ ¹æ®é£é™©ç­‰çº§è°ƒæ•´ä»“ä½ï¼š{level}ç¯å¢ƒä¸‹åº”{'åŠ å¤§' if ratio < 0.8 else 'å‡å°‘'}æ æ†æˆ–æŒä»“ã€‚",
        "sentiment": sentiment,
        "question": "å½“å‰é£é™©æ°´å¹³å¦‚ä½•ï¼Ÿæ˜¯å¦é€‚åˆæ™®é€šæŠ•èµ„è€…å‚ä¸ï¼Ÿ"
    }

def explain_correlation_risk(corr_matrix: pd.DataFrame) -> Dict[str, Any]:
    """
    Analyzes Systemic Risk via Correlation.
    Core Question: "Risk/Return Match? (Diversification value)"
    """
    if corr_matrix is None or corr_matrix.empty:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
    
    # Use upper triangle only to avoid self-correlation and duplicates
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)
    avg_corr = corr_matrix.where(mask).stack().mean()
    
    if np.isnan(avg_corr):
        avg_corr = 0.0

    if avg_corr > 0.7:
        status = "High Systemic Risk (é«˜åº¦è”åŠ¨)"
        desc = "è¡Œä¸šå†…ä¸ªè‚¡åŒæ¶¨åŒè·Œç°è±¡æå¼ºï¼Œé€‰è‚¡å¾ˆéš¾è·å¾—è¶…é¢æ”¶ç›Šã€‚"
        advice = "åˆ†æ•£æŠ•èµ„åœ¨æœ¬è¡Œä¸šå†…å‡ ä¹æ— æ•ˆã€‚å»ºè®®è¦ä¹ˆé…ç½®è¡Œä¸šETFï¼Œè¦ä¹ˆé€šè¿‡é…ç½®å…¶ä»–ç›¸å…³æ€§ä½çš„è¡Œä¸šæ¥å¯¹å†²é£é™©ã€‚"
        sentiment = "negative"
    elif avg_corr > 0.4:
        status = "Moderate Correlation (ä¸­åº¦è”åŠ¨)"
        desc = "è¡Œä¸šå…·å¤‡ä¸€å®šçš„æ•´ä½“æ•ˆåº”ï¼Œä½†ä¸ªè‚¡åˆ†åŒ–ä¾ç„¶å­˜åœ¨ã€‚"
        advice = "å¯ä»¥è¿›è¡Œç²¾é€‰ä¸ªè‚¡ï¼Œå¯»æ‰¾å¼ºäºè¡Œä¸šæŒ‡æ•°çš„é¾™å¤´ã€‚é€‚åº¦åˆ†æ•£æŒä»“å¯ä»¥é™ä½éç³»ç»Ÿæ€§é£é™©ã€‚"
        sentiment = "neutral"
    else:
        status = "Low Correlation (ä½è”åŠ¨/åˆ†åŒ–)"
        desc = "è¡Œä¸šå†…ä¸ªè‚¡èµ°åŠ¿ç‹¬ç«‹æ€§å¼ºï¼Œå—å®è§‚æˆ–è¡Œä¸šè´å¡”å½±å“å°ã€‚"
        advice = "æ˜¯â€œè½»æŒ‡æ•°é‡ä¸ªè‚¡â€çš„æœ€ä½³æ—¶æœºã€‚æ·±å…¥æŒ–æ˜åŸºæœ¬é¢ç‹¬ç‰¹çš„ä¸ªè‚¡æœ‰æœ›è·å¾—æ˜¾è‘—çš„Alphaæ”¶ç›Šã€‚"
        sentiment = "positive"

    return {
        "valid": True,
        "title": "è¡Œä¸šç³»ç»Ÿæ€§é£é™©åˆ†æ (ç›¸å…³æ€§)",
        "signal": f"è”åŠ¨æ€§: {avg_corr:.2f} ({status})",
        "assessment": desc,
        "advice": advice,
        "sentiment": sentiment,
        "question": "æ”¶ç›Šä¸é£é™©æ˜¯å¦åŒ¹é…ï¼Ÿ(æ˜¯å¦å¯ä»¥é€šè¿‡åˆ†æ•£æŠ•èµ„é™ä½é£é™©)"
    }

def explain_pca_structure(explained_variance: pd.Series) -> Dict[str, Any]:
    """
    Analyzes Market Structure via PCA.
    """
    if explained_variance is None or len(explained_variance) == 0:
         return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
    
    first_comp = explained_variance.iloc[0]
    
    if first_comp > 0.7:
        msg = "å¸‚åœºç”±å•ä¸€ä¸»å¯¼å› ç´ ï¼ˆé€šå¸¸æ˜¯å®è§‚æˆ–å¤§ç›˜æƒ…ç»ªï¼‰é©±åŠ¨ï¼Œä¸ªè‚¡ç‰¹æ€§è¢«æ©ç›–ã€‚"
        advice = "å®è§‚åˆ†æä¼˜äºä¸ªè‚¡åˆ†æã€‚é‡ç‚¹å…³æ³¨å¤§ç›˜èµ°åŠ¿å’Œå®è§‚æ”¿ç­–ï¼Œè€Œéä¸ªè‚¡åŸºæœ¬é¢ã€‚"
    elif first_comp > 0.4:
        msg = "å¸‚åœºå—ä¸»è¦å› ç´ å½±å“ï¼Œä½†ä»æœ‰éƒ¨åˆ†ä¸ªè‚¡é€»è¾‘åœ¨æ¼”ç»ã€‚"
        advice = "ç»“åˆå®è§‚ä¸ä¸ªè‚¡ã€‚æ—¢è¦çœ‹å¤§åŠ¿ï¼Œä¹Ÿè¦é€‰å¥½è‚¡ã€‚"
    else:
        msg = "å¸‚åœºé©±åŠ¨åŠ›åˆ†æ•£ï¼Œä¸ªè‚¡è¡Œæƒ…ç‹¬ç«‹ï¼Œç¼ºä¹ç»Ÿä¸€çš„ä¸»çº¿ã€‚"
        advice = "ç²¾é€‰ä¸ªè‚¡çš„é»„é‡‘æ—¶æœŸã€‚ä¸»è¦å…³æ³¨ä¸ªè‚¡è‡ªèº«çš„å‚¬åŒ–å‰‚ã€‚"
        
    return {
        "valid": True,
        "title": "å¸‚åœºé©±åŠ¨åŠ›ç»“æ„ (PCA)",
        "signal": f"ä¸»æˆåˆ†è§£é‡Šç‡: {first_comp:.2%}",
        "assessment": msg,
        "advice": advice,
        "sentiment": "neutral",
        "question": "å½“å‰è¶‹åŠ¿æ˜¯å¼ºè¿˜æ˜¯å¼±ï¼Ÿ(å¸‚åœºç»“æ„ç»´åº¦)"
    }

def explain_seasonality(stl_res: Any) -> Dict[str, Any]:
    """
    Analyzes Seasonality.
    """
    if stl_res is None:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
        
    # Simple logic: Check variance of seasonal component vs residual
    seasonal_var = np.var(stl_res.seasonal)
    resid_var = np.var(stl_res.resid)
    
    if seasonal_var > resid_var * 1.5:
        status = "Significant Seasonality (æ˜¾è‘—å­£èŠ‚æ€§)"
        advice = "è¯¥æ ‡çš„å…·æœ‰è¾ƒå¼ºçš„å‘¨æœŸ/å­£èŠ‚è§„å¾‹ã€‚å»ºè®®ç ”ç©¶å†å²åŒæœŸçš„èµ°åŠ¿ï¼ˆå¦‚æœˆåº¦/å­£åº¦æ•ˆåº”ï¼‰æ¥è¾…åŠ©æ‹©æ—¶ã€‚"
    else:
        status = "Weak Seasonality (å¼±å­£èŠ‚æ€§)"
        advice = "å­£èŠ‚æ€§è§„å¾‹ä¸æ˜æ˜¾ï¼Œæ›´å¤šå…³æ³¨è¶‹åŠ¿å’Œéšæœºå†²å‡»ã€‚"
        
    return {
        "valid": True,
        "title": "å‘¨æœŸä¸å­£èŠ‚æ€§åˆ†æ",
        "signal": status,
        "assessment": f"å­£èŠ‚æˆåˆ†æ³¢åŠ¨({'å¤§äº' if seasonal_var > resid_var else 'å°äº'})éšæœºå™ªéŸ³ã€‚",
        "advice": advice,
        "sentiment": "neutral",
        "question": "åœ¨å†å²ç»Ÿè®¡æ„ä¹‰ä¸Šï¼Œæœªæ¥ä¸Šæ¶¨æˆ–ä¸‹è·Œçš„æ¦‚ç‡å¦‚ä½•ï¼Ÿ(å‘¨æœŸç»´åº¦)"
    }

def explain_prediction_probability(proba_series: pd.Series, auc_score: float) -> Dict[str, Any]:
    """
    Analyzes Prediction Probability.
    Core Question: "Future probability?"
    """
    if proba_series is None or proba_series.empty:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
        
    # Assuming proba is "Probability of Up" for the specific stock if passed, 
    # OR distribution of probabilities for the industry.
    # Here we analyze the distribution if it's a series of multiple stocks, 
    # or a single value if specific.
    
    mean_prob = proba_series.mean()
    
    reliability = "ä½"
    if auc_score and auc_score > 0.7: reliability = "é«˜"
    elif auc_score and auc_score > 0.6: reliability = "ä¸­"
    
    if mean_prob > 0.6:
        direction = "Upward Bias (çœ‹æ¶¨)"
        sentiment = "positive"
        advice = "æ¨¡å‹é¢„æµ‹ä¸Šæ¶¨æ¦‚ç‡è¾ƒå¤§ã€‚åœ¨æ§åˆ¶é£é™©çš„å‰æä¸‹ï¼Œå¯è€ƒè™‘åšå¤šã€‚"
    elif mean_prob < 0.4:
        direction = "Downward Bias (çœ‹è·Œ)"
        sentiment = "negative"
        advice = "æ¨¡å‹é¢„æµ‹ä¸‹è·Œæ¦‚ç‡è¾ƒå¤§ã€‚å»ºè®®å‡ä»“æˆ–åšç©ºï¼Œé¿å…é€†åŠ¿æ“ä½œã€‚"
    else:
        direction = "Neutral (ä¸­æ€§)"
        sentiment = "neutral"
        advice = "æ¨¡å‹é¢„æµ‹æ¶¨è·Œæ¦‚ç‡æ¥è¿‘äº”äº”å¼€ï¼Œæ–¹å‘ä¸æ˜ã€‚å»ºè®®è§‚æœ›ã€‚"
        
    return {
        "valid": True,
        "title": "æœªæ¥æ¶¨è·Œæ¦‚ç‡é¢„æµ‹ (é€»è¾‘å›å½’)",
        "signal": f"å¹³å‡ä¸Šæ¶¨æ¦‚ç‡: {mean_prob:.2%} (æ¨¡å‹å¯é æ€§: {reliability})",
        "assessment": f"åŸºäºå†å²ç‰¹å¾è®­ç»ƒçš„æ¨¡å‹æ˜¾ç¤ºï¼Œå½“å‰æ ·æœ¬å€¾å‘äº{direction}ã€‚",
        "advice": f"{advice} (æ³¨ï¼šå†å²ç»Ÿè®¡æ„ä¹‰ä¸Šçš„æ¦‚ç‡ï¼Œä¸ä»£è¡¨ç»å¯¹æœªæ¥)",
        "sentiment": sentiment,
        "question": "åœ¨å†å²ç»Ÿè®¡æ„ä¹‰ä¸Šï¼Œæœªæ¥ä¸Šæ¶¨æˆ–ä¸‹è·Œçš„æ¦‚ç‡å¦‚ä½•ï¼Ÿ"
    }

def explain_factor_regression(coefs: pd.Series, r2: float) -> Dict[str, Any]:
    """
    Explain Factor Exposure.
    """
    if coefs is None or coefs.empty:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
    
    top_factor = coefs.abs().idxmax()
    direction = "æ­£å‘" if coefs[top_factor] > 0 else "è´Ÿå‘"
    
    if r2 > 0.5:
        assess = f"è¯¥ç»„åˆæ·±å—åŸºæœ¬é¢å› å­é©±åŠ¨ (R2={r2:.2f})ã€‚ä¸»è¦å— {top_factor} å› å­{direction}å½±å“ã€‚"
        advice = f"å…³æ³¨ {top_factor} çš„å˜åŒ–ã€‚å¦‚æœé¢„æœŸè¯¥æŒ‡æ ‡æ”¹å–„ï¼Œåˆ™åˆ©å¥½è‚¡ä»·ã€‚"
    else:
        assess = f"åŸºæœ¬é¢å› å­å¯¹æ”¶ç›Šç‡è§£é‡ŠåŠ›è¾ƒå¼± (R2={r2:.2f})ï¼Œå¯èƒ½å—éåŸºæœ¬é¢å› ç´ ï¼ˆå¦‚èµ„é‡‘é¢ã€æƒ…ç»ªï¼‰ä¸»å¯¼ã€‚"
        advice = "å•çº¯ä¾èµ–åŸºæœ¬é¢å› å­é€‰è‚¡å¯èƒ½å¤±æ•ˆï¼Œéœ€ç»“åˆæŠ€æœ¯é¢æˆ–èµ„é‡‘é¢åˆ†æã€‚"
        
    return {
        "valid": True,
        "title": "åŸºæœ¬é¢é©±åŠ¨å› ç´ åˆ†æ",
        "signal": f"ä¸»å¯¼å› å­: {top_factor} ({direction})",
        "assessment": assess,
        "advice": advice,
        "sentiment": "neutral",
        "question": "æ”¶ç›Šä¸é£é™©æ˜¯å¦åŒ¹é…ï¼Ÿ(å½’å› åˆ†æ)"
    }

def explain_clustering(n_clusters: int, labels: pd.Series) -> Dict[str, Any]:
    """
    Explain Clustering results.
    """
    if labels is None or labels.empty:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
        
    counts = labels.value_counts()
    dominant_cluster = counts.idxmax()
    dominant_ratio = counts.max() / len(labels)
    
    if dominant_ratio > 0.8:
        msg = "å¤§éƒ¨åˆ†æ ‡çš„èšé›†åœ¨åŒä¸€ç±»åˆ«ï¼Œå¸‚åœºåˆ†åŒ–ç¨‹åº¦ä½ã€‚"
        advice = "å¸‚åœºåŒè´¨åŒ–ä¸¥é‡ï¼Œç²¾é€‰ä¸ªè‚¡éš¾åº¦è¾ƒå¤§ï¼Œå»ºè®®é¡ºåŠ¿è€Œä¸ºã€‚"
    else:
        msg = f"å¸‚åœºæ˜æ˜¾åˆ†åŒ–ä¸º {n_clusters} ä¸ªé˜µè¥ï¼Œå­˜åœ¨ç»“æ„æ€§æœºä¼šã€‚"
        advice = "å¸‚åœºå­˜åœ¨åˆ†åŒ–ï¼Œå¯å¯»æ‰¾å¤„äº'é«˜æ”¶ç›Š-ä½é£é™©'èšç±»çš„ä¸ªè‚¡ã€‚"
        
    return {
        "valid": True,
        "title": "å¸‚åœºé£é™©æ”¶ç›Šç»“æ„ (èšç±»)",
        "signal": f"åˆ†åŒ–ç¨‹åº¦: {'ä½' if dominant_ratio > 0.8 else 'é«˜'}",
        "assessment": msg,
        "advice": advice,
        "sentiment": "neutral",
        "question": "æ”¶ç›Šä¸é£é™©æ˜¯å¦åŒ¹é…ï¼Ÿ(å¸‚åœºç»“æ„ç»´åº¦)"
    }

def explain_factor_portrait(portrait: pd.DataFrame) -> Dict[str, Any]:
    if portrait is None or portrait.empty:
        return {"valid": False, "msg": "æ•°æ®ä¸è¶³"}
    trend_pos = []
    trend_neg = []
    if "trend" in portrait.columns:
        try:
            tr = pd.to_numeric(portrait["trend"], errors="coerce")
            trend_pos = portrait.loc[tr > 0, "metric"].astype(str).tolist()
            trend_neg = portrait.loc[tr < 0, "metric"].astype(str).tolist()
        except Exception:
            trend_pos = []
            trend_neg = []
    if "percentile" in portrait.columns:
        try:
            avg_pct = float(pd.to_numeric(portrait["percentile"], errors="coerce").dropna().mean())
        except Exception:
            avg_pct = 0.5
        top = portrait.sort_values("percentile", ascending=False).iloc[0]["metric"]
        signal = f"è¡Œä¸šåˆ†ä½å‡å€¼: {avg_pct:.2f}ï¼›ä¼˜åŠ¿å› å­: {top}"
        assessment = f"åˆ†ä½å{'é«˜' if avg_pct>0.5 else 'ä½'}ï¼›ä¸Šè¡Œå› å­: {', '.join(trend_pos) if trend_pos else 'æ— '}ï¼›ä¸‹è¡Œå› å­: {', '.join(trend_neg) if trend_neg else 'æ— '}ã€‚"
    else:
        top = portrait.sort_values("value", ascending=False).iloc[0]["metric"] if "value" in portrait.columns else "æœªçŸ¥"
        try:
            avg_val = float(pd.to_numeric(portrait["value"], errors="coerce").dropna().mean()) if "value" in portrait.columns else None
        except Exception:
            avg_val = None
        signal = f"ä¼˜åŠ¿å› å­: {top}" if avg_val is None else f"å¹³å‡æŒ‡æ ‡å€¼: {avg_val:.2f}ï¼›ä¼˜åŠ¿å› å­: {top}"
        assessment = f"ä¸Šè¡Œå› å­: {', '.join(trend_pos) if trend_pos else 'æ— '}ï¼›ä¸‹è¡Œå› å­: {', '.join(trend_neg) if trend_neg else 'æ— '}ã€‚"
    advice = "ç»“åˆä¼˜åŠ¿å› å­ç»´æŒé•¿æœŸå…³æ³¨ï¼›åŠ£åŠ¿å› å­ä¾§é‡æ”¹å–„ä¸è·Ÿè¸ªã€‚"
    return {
        "valid": True,
        "title": "åŸºæœ¬é¢ç”»åƒåˆ†æï¼ˆå•è¯åˆ¸ï¼‰",
        "signal": signal,
        "assessment": assessment,
        "advice": advice,
        "sentiment": "neutral",
        "question": "åœ¨å› å­å›å½’ä¸å¯ç”¨æ—¶ï¼Œå¦‚ä½•ç†è§£è¯¥è¯åˆ¸çš„é•¿æœŸé£æ ¼ä¸åŸºæœ¬é¢ç‰¹å¾ï¼Ÿ"
    }
